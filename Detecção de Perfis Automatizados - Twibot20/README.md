# Detec√ß√£o de Perfis Automatizados - Twibot20 :bird: :space_invader:
Este projeto foi realizado como projeto de conclus√£o do curso de Data Science da Digital House.
Com exce√ß√£o da obten√ß√£o dos dados, todo o processo de manipula√ß√£o e modelagem dos dados foi realizado por mim.

O projeto possui como objetivo a cria√ß√£o de um modelo de classifica√ß√£o capaz de identificar caracter√≠sticas que possam levar a identifica√ß√£o de um perfil automatizado (bot) na rede social Twitter.

## :book: Dados 

Os dados utilizados no projeto foram obtidos pela equipe do paper [TwiBot-20: A Comprehensive Twitter Bot Detection Benchmark](https://www.researchgate.net/publication/355785254_TwiBot-20_A_Comprehensive_Twitter_Bot_Detection_Benchmark). O paper foi elaborado com o objetivo de criar um dataset que seja representativo da realidade observada no twitter.

Ap√≥s entrar em contato por email com um dos  autores do paper, explicar a id√©ia do projeto e que se tratava de um projeto com fins academicos os dados foram gentilmente cedidos.
Como os dados n√£o est√£o dispon√≠veis de forma p√∫blica na internet, este reposit√≥rio contar√° apenas com uma amostra de 15 elementos do treino e do teste para ilustrar os processos desenvolvidos.

Os dados recebidos estavam em formato .json e j√° estavam divididos em treino e teste, e assim foi mantido para preservar compara√ß√µes futuras.

### Documenta√ß√£o dos dados  :eyes: :clipboard:

|                  ID |                                           profile |                                             tweet |                                          neighbor |                              domain | label |
|--------------------:|--------------------------------------------------:|--------------------------------------------------:|--------------------------------------------------:|------------------------------------:|------:|
|            17461978 | {'id': '17461978 ', 'id_str': '17461978 ', 'na... | [RT @CarnivalCruise: üéâ Are you ready to see wh... |                                              None | [Politics, Business, Entertainment] |     0 |
| 1297437077403885568 | {'id': '1297437077403885568 ', 'id_str': '1297... |                                              None | {'following': ['170861207', '23970102', '47293... |                          [Politics] |     1 |
|            17685258 | {'id': '17685258 ', 'id_str': '17685258 ', 'na... | [RT @realDonaldTrump: THANK YOU #RNC2020! http... | {'following': ['46464108', '21536398', '186434... |   [Politics, Entertainment, Sports] |     0 |

- 'ID': ID de identifica√ß√£o utilizado pelo twitter
- 'profile':  informa√ß√µes do perfil obtidas pela API do Twtiter
- 'tweet': Os √∫ltimso 200 tweets do usu√°rio
- 'neighbor': 20 seguidores e seguidos aleat√≥rios do usu√°rio
- 'domain': Assunto discutido pelo usu√°rio, podendo ser: politics, business, entertainment e sports
- 'label': target. '1'= bot | '0'= humano

A quantidade de bots e humanos nos dados estava um pouco desbalanceada, por√©m est√° √© uma caracter√≠stica esperada da popula√ß√£o no mundo real. Estando da seguinte forma:

![treino](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/bot-humano%20treino.jpg)
![teste](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/bot-humano%20teste.jpg)


## Manipula√ß√£o dos dados  :pencil:
### 1. Desdobramento da coluna profile.
Dentre as diversas informa√ßoes [disponiveis](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user) na coluna profile
foram extraidas as seguintes informa√ß√µes:
- location (se tem ou n√£o)
- followers_count -> N√∫mero de seguidores
- friends_count -> N√∫mero de perfis seguidos pelo usu√°rio  (AKA  ‚Äúfollowings‚Äù)
- geo_enabled -> se o perfil j√° ativou o GPS em alguma postagem
- verified -> Se o perfil √© verificado
- statuses_counts -> n√∫mero de posts
- default_profile -> Se o ousu√°rio j√° alterou o tema ou o plano de fundo do perfil
- default_profile_image -> Se o usu√°rio j√° alterou a  foto padr√£o inicial
- created_at -> a idade do perfil
- name -> nome do perfil
- screen_name -> nome / pseudonimo do prefil (pode ser alterado)
- description -> descri√ß√£o do perfil
- statuses_count -> quantidade de posts realizados
- listed_count -> quantidade de listas p√∫blicas que o usu√°rio √© membro
- favourites_count -> quantidade de likes que o usu√°rio j√° deu em posts 

#### 1.1 Algumas dessas features foram utilizadas para a cria√ß√£o de novas:

- profile_m_age -> idade do perfil em meses, baseada no created_at 
- frequencia de tweets -> statuses_count / profile_m_age
- name_lenght -> quantidade de caracteres do do name
- screen_name_length -> quantidade de caracteres do screen_name
- description_length -> quantidade de caracteres do da descri√ß√£o
- ff ratio -> friends_count /  followers_count. Raz√£o entre as pessoas que voc√™ segue (friends) dividido pelas pessoas que seguem voc√™ (followers).
- followers_growth_rate -> followers_count / profile_m_age. Taxa de crescimento dos followers
- friends_growth_rate ->  friends_count / profile_m_age. Taxa de crescimento dos friends
- favourites_growth_rate -> favourites_count / profile_m_age. Taxa de crescimento dos favourites
- listed_growth_rate -> listed_count / profile_m_age. Taxa de crescimento do listed


### 2.Desdobramento da coluna tweet
Dentre os 200 tweets de cada observa√ß√£o foram extraidas:
- n√∫mero de urls postados
- n√∫mero de urls repetidas postadas
- n√∫mero de # postadas
- n√∫mero de # repetidas postadas
- n√∫mero de @ mencionados
- n√∫mero de @ repetidos mencionados

Estas informa√ß√µes foram extraidas com base na premisssa de que perfis automatizados s√£o comumente utilizados para a propaga√ß√£o massiva (spam) de mensagens.

#### 2.1 TFIDF - NLP
Com o intuito de extrair informa√ß√µes que possam ser relevantes para a an√°lise com base nos textos dos posts, foi realizado um processamento de linguagem natural (NLP) simples. Foi utilizado o TFIDF para extrair as palavras 200 mais relevantes entre todos os posts.

A id√©ia por tr√°s do TFIDF √© que se uma palavra aparece com frequencia em um documento, ent√£o ela deve ser importante e por isso deve receber um score alto. Mas se a palavra aparece em muitos outros documentos, provavelmente n√£o √© um identificador √∫nico ( pode ser um conectivo, preposi√ß√£o, etc.), ent√£o deve receber um valor baixo.

TFIDF √© a jun√ß√£o de 2 transforma√ß√µes:
- TF -> Term Frquency ( frequ√™ncia do termo)
TF(w) = (N¬∫ de vezes que a palavra w aparece no documento) / (N¬∫ total de termos no documento)

IDF -> Inverse Term Frequency ( Inverso da frequ√™ncia do termo )
IDF(w) = log_e( N¬∫ total de documentos) / (N¬∫ dedocumentos que contemnham o termo w)

**TFIDF(w) = TF(w) * IDF(w)**

Para n√£o adicionarmos mais 200 colunas aos nosso dados, uma para cada uma das palavras selecionadas, foram selecionadas apenas as colunas que possuiam a maior vari√¢ncia entre os scores. Pois uma coluna com baixa vari√¢ncia significa que os valores entre todas as observa√ß√µes n√£o s√£o muito diferentes, e por isso n√£o proporcionariam informa√ß√µes relevantes ao modelo.

Assim somente as palavras que possuiam uma vari√¢ncia maior que o 3¬∫ quartil, o top 25%, foram mantidas.
Ainda assim algumas palavras sem sentido, passaram pelos filtros. Como emojis (amp) e conectivos em espanhol (en, la, los....) que foram removidas.
As seguintes palavras foram aplicadas ao modelos, com seus respectivos TFIDF score.

` ['biden', 'covid19', 'day', 'del', 'don', 'dont', 'follow', 'game',
'god', 'good', 'great', 'gt', 'happy', 'im', 'just', 'know', 'like',
'lol', 'love', 'music', 'new', 'news', 'people', 'president',
'realdonaldtrump', 'rt', 'season', 'team', 'thank', 'thanks', 'think',
'time', 'today', 'tonight', 'trump', 'video', 'win', 'youtube'] `
 
## Boruta_py - Feature Selection :mag:

Antes de aplicar o modelo nos dados, foi realizado uma sele√ß√£o de features utilizando a biblioteca [Boruta](https://github.com/scikit-learn-contrib/boruta_py).
Boruta √© um algor√≠tmo bastante interessante, que checa a importancia de uma determianda coluna de acordo com sua performance contra uma vers√£o com valores aleatorios da mesma (chamada de shadow feature), al√©m de conceitos dad dsitribui√ß√£o binomial para checar se uma feature realmente √© importante ou n√£o.

O resultado do modelo com o boruta aplicado, teve uma diferen√ßa bem pequena na casa de 0.00Algumacoisa nas m√©tricas de avalia√ß√£o. Por√©m, ao reduzir a quantidade de colunas necess√°rias para o modelo, reduziu a carga de processamento utilizada. Al√©m de que essa altera√ß√£o foi positiva em todas as m√©tricas.

As colunas removidas pelo Boruta foram:

`['default_profile', 'use_background_img',
   'location', 'geo_enable', 'verified',
   'default_profile_image', 'covid19',
   'god', 'gt', 'music','season',
   'video', 'win','youtube']`

## O MODELO :milky_way:  :octocat:
