# Detec√ß√£o de Perfis Automatizados - Twibot20 :bird: :space_invader:
Este projeto foi realizado como projeto de conclus√£o do curso de Data Science da Digital House.

## Objetivos :pushpin: :grey_exclamation:
O projeto possui como objetivo a cria√ß√£o de um modelo de classifica√ß√£o capaz de identificar caracter√≠sticas que possam levar a identifica√ß√£o de um perfil automatizado (bot) na rede social Twitter. O modelo deve ser capaz de identificar o maior n√∫mero de bots possiveis ao mesmo tempo que evita a ocorr√™ncia de falso positivo,a identifica√ß√£o de usu√°rios reais como bots.

N√£o √© dif√≠cil encontrar artigos cient√≠ficos que proponham a cria√ß√£o de modelos com esse objetivo, por√©m muitos deles n√£o utilizam dados realmente representativos do mundo real, devido a complexidade de identificar se um perfil realmente √© um bot ou n√£o, ou n√£o performam bem em um teste verdadeiro. De qualquer maneira, alguns artigos foram consultados com o intuito de obter uma maior compreens√£o sobre o problema e identificar poss√≠veis features e modelos relevantes para o problema.

## :book: Dados 

Os dados utilizados no projeto foram obtidos pela equipe do paper [TwiBot-20: A Comprehensive Twitter Bot Detection Benchmark](https://www.researchgate.net/publication/355785254_TwiBot-20_A_Comprehensive_Twitter_Bot_Detection_Benchmark). O paper foi elaborado com o objetivo de criar um dataset que seja representativo da realidade observada no twitter.

Ap√≥s entrar em contato por email com um dos  autores do paper, explicar a id√©ia do projeto e que se tratava de um projeto com fins acad√™micos,  os dados foram gentilmente compartilhados.
Como os dados n√£o est√£o dispon√≠veis de forma p√∫blica na internet, este reposit√≥rio contar√° apenas com uma amostra de 15 elementos do treino e do teste para ilustrar os processos desenvolvidos.

Os dados recebidos estavam em formato .json e j√° estavam divididos em treino e teste, e assim foi mantido para preservar compara√ß√µes futuras.

### Documenta√ß√£o dos dados  :eyes: :clipboard:

|                  ID |                                           profile |                                             tweet |                                          neighbor |                              domain | label |
|--------------------:|--------------------------------------------------:|--------------------------------------------------:|--------------------------------------------------:|------------------------------------:|------:|
|            17461978 | {'id': '17461978 ', 'id_str': '17461978 ', 'na... | [RT @CarnivalCruise: üéâ Are you ready to see wh... |                                              None | [Politics, Business, Entertainment] |     0 |
| 1297437077403885568 | {'id': '1297437077403885568 ', 'id_str': '1297... |                                              None | {'following': ['170861207', '23970102', '47293... |                          [Politics] |     1 |
|            17685258 | {'id': '17685258 ', 'id_str': '17685258 ', 'na... | [RT @realDonaldTrump: THANK YOU #RNC2020! http... | {'following': ['46464108', '21536398', '186434... |   [Politics, Entertainment, Sports] |     0 |

- 'ID': ID de identifica√ß√£o utilizado pelo twitter
- 'profile':  Dicion√°rio com informa√ß√µes do perfil obtidas pela API do Twtiter
- 'tweet': Os √∫ltimso 200 tweets do usu√°rio
- 'neighbor': 20 seguidores e seguidos aleat√≥rios do usu√°rio
- 'domain': Assunto discutido pelo usu√°rio, podendo ser: politics, business, entertainment e sports
- 'label': target. '1'= bot | '0'= humano

A quantidade de bots e humanos nos dados estava um pouco desbalanceada, por√©m est√° √© uma caracter√≠stica esperada da popula√ß√£o no mundo real. Estando da seguinte forma:

![treino](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/bot-humano%20treino.jpg)
![teste](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/bot-humano%20teste.jpg)


# Manipula√ß√£o dos dados  :pencil:
## 1. Desdobramento da coluna profile.
Dentre as diversas informa√ßoes [disponiveis](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user) na coluna profile
foram extraidas as seguintes informa√ß√µes:
- location -> se possui uma localiza√ß√£o descrita no perfil.
- followers_count -> N√∫mero de seguidores
- friends_count -> N√∫mero de perfis seguidos pelo usu√°rio  (AKA  ‚Äúfollowings‚Äù)
- geo_enabled -> se o perfil j√° ativou o GPS em alguma postagem
- verified -> Se o perfil √© verificado
- statuses_counts -> n√∫mero de posts
- default_profile -> Se o ousu√°rio j√° alterou o tema ou o plano de fundo do perfil
- default_profile_image -> Se o usu√°rio j√° alterou a  foto padr√£o inicial
- created_at -> a idade do perfil
- name -> nome do perfil
- screen_name -> nome / pseudonimo do prefil (pode ser alterado)
- description -> descri√ß√£o do perfil
- statuses_count -> quantidade de posts realizados
- listed_count -> quantidade de listas p√∫blicas que o usu√°rio √© membro
- favourites_count -> quantidade de likes que o usu√°rio j√° deu em posts 

### 1.1 Algumas dessas features foram utilizadas para a cria√ß√£o de novas:

- profile_m_age -> idade do perfil em meses, baseada no created_at. Usada para Cria√ß√£o de features nas etapas seguintes.
- frequencia de tweets -> statuses_count / profile_m_age
- name_lenght -> quantidade de caracteres do do name
- screen_name_length -> quantidade de caracteres do screen_name
- description_length -> quantidade de caracteres do da descri√ß√£o
- ff ratio -> friends_count /  followers_count. Raz√£o entre as pessoas que voc√™ segue (friends) dividido pelas pessoas que seguem voc√™ (followers).
- followers_growth_rate -> followers_count / profile_m_age. Taxa de crescimento dos followers
- friends_growth_rate ->  friends_count / profile_m_age. Taxa de crescimento dos friends
- favourites_growth_rate -> favourites_count / profile_m_age. Taxa de crescimento dos favourites
- listed_growth_rate -> listed_count / profile_m_age. Taxa de crescimento do listed


## 2.Desdobramento da coluna tweet
Dentre os 200 tweets de cada observa√ß√£o foram extraidas:
- n√∫mero de urls postados
- n√∫mero de urls repetidas postadas
- n√∫mero de # postadas
- n√∫mero de # repetidas postadas
- n√∫mero de @ mencionados
- n√∫mero de @ repetidos mencionados

Estas informa√ß√µes foram extraidas com base na premisssa de que perfis automatizados s√£o comumente utilizados para a propaga√ß√£o massiva (spam) de mensagens.

### 2.1 TFIDF - NLP
Com o intuito de extrair informa√ß√µes que possam ser relevantes para a an√°lise com base nos textos dos posts, foi realizado um processamento de linguagem natural (NLP) simples. Foi utilizado o TFIDF para extrair as palavras 200 mais relevantes entre todos os posts.

A id√©ia por tr√°s do TFIDF √© que se uma palavra aparece com frequ√™ncia em um documento, ent√£o ela deve ser importante e por isso deve receber um score alto. Mas se a palavra aparece em muitos outros documentos, provavelmente n√£o √© um identificador sobre o tema do documento ( pode ser um conectivo, preposi√ß√£o, etc.), ent√£o deve receber um valor baixo.

TFIDF √© a jun√ß√£o de 2 transforma√ß√µes:
**TF** -> Term Frquency ( frequ√™ncia do termo)
**TF(w)** = (N¬∫ de vezes que a palavra w aparece no documento) / (N¬∫ total de termos no documento)

**IDF** -> Inverse Term Frequency ( Inverso da frequ√™ncia do termo )
**IDF(w)** = log_e( N¬∫ total de documentos) / (N¬∫ dedocumentos que contemnham o termo w)

**TFIDF(w) = TF(w) * IDF(w)**

Para n√£o adicionarmos mais 200 colunas aos nosso dados, uma para cada uma das palavras selecionadas, foram selecionadas apenas as colunas que possuiam a maior vari√¢ncia entre os scores. Pois uma coluna com baixa vari√¢ncia significa que os valores entre todas as observa√ß√µes n√£o s√£o muito diferentes, e por isso, no geral, n√£o proporcionariam informa√ß√µes relevantes, para distin√ß√£o dos usu√°rios, ao modelo.

Assim somente as palavras que possuiam uma vari√¢ncia maior que o 3¬∫ quartil, o top 25%, foram mantidas.
Ainda assim algumas palavras sem sentido, passaram pelos filtros. Como emojis (amp) e conectivos em espanhol (en, la, los....) que foram removidas.
As seguintes palavras foram aplicadas ao modelos, com seus respectivos TFIDF score.

` ['biden', 'covid19', 'day', 'del', 'don', 'dont', 'follow', 'game',
'god', 'good', 'great', 'gt', 'happy', 'im', 'just', 'know', 'like',
'lol', 'love', 'music', 'new', 'news', 'people', 'president',
'realdonaldtrump', 'rt', 'season', 'team', 'thank', 'thanks', 'think',
'time', 'today', 'tonight', 'trump', 'video', 'win', 'youtube'] `
 
## Boruta_py - Feature Selection :mag:

Antes de aplicar o modelo nos dados, foi realizado uma sele√ß√£o de features utilizando a biblioteca [Boruta](https://github.com/scikit-learn-contrib/boruta_py).
Boruta √© um algor√≠tmo bastante interessante, que checa a import√¢ncia de uma determianda feature de acordo com sua performance contra uma vers√£o com valores aleatorios da mesma (chamada de shadow feature), al√©m de utilziar conceitos da distribui√ß√£o binomial para checar se uma feature realmente √© importante ou n√£o. Entre outras coisas, vale dar uma olhada na documenta√ß√£o para saber mais.

O resultado do modelo com o Boruta aplicado, teve uma diferen√ßa bem pequena na casa de 0.00Algumacoisa nas m√©tricas de avalia√ß√£o. Por√©m, ao reduzir a quantidade de colunas necess√°rias para o modelo, removendo 14 colunas, reduziu a carga de processamento utilizada. Al√©m de que essa altera√ß√£o foi positiva em todas as m√©tricas.

As colunas removidas pelo Boruta foram:

`['default_profile', 'use_background_img',
   'location', 'geo_enable', 'verified',
   'profile_image', 'covid19',
   'god', 'gt', 'music','season',
   'video', 'win','youtube']`

# O MODELO :milky_way:  :octocat:

Diversos modelos e combina√ß√µes entre modelos/features/transforma√ß√µes foram testados na busca pelo modelo que obtivesse a maior performance poss√≠vel.
Dentre os artigos cient√≠ficos pesquisados, muitos se utilizavam ou ao menos mencionavam o Random Forest como o modelo que melhor se ajusta-se ao problema em quest√£o.
Antes e durante o processo de transforma√ß√£o dos dados, alguns outros modelos foram capazes de performar melhor que o Random Forest. Como o SVM e at√© mesmo a regress√£o log√≠stica. Por√©m, ainda com uma performance bem a baixo do esperado. 

Antes de abordar o modelo, vamos falar sobreas m√©tricas de avalia√ß√£o que foram utilizadas para selecionar o modelo com maior performance.

## M√©tricas de Avalia√ß√£o :chart_with_upwards_trend:

O objetivo do projeto √© criar um modelo que maximize a identifica√ß√£o de perfis automatizados, e, ao mesmo tempo, minimize a ocorr√™ncia de falsos positivos. Pois a identifica√ß√£o errada de um usu√°rio verdadeiro pode causar s√©rios problemas, tanto para o usu√°rio quanto para a empresa. Para isso foram priorizadas as seguintes m√©tricas:

- **Recall**: Porcentagem de observa√ß√µes corretamente identificada como 1(bot), dentre todas as observa√ß√µes 1(bot). Penaliza Falso Negativo.
- **Precision**: Porcentagem de observa√ß√µes corretamente identificada como 1(bot), dentre todas as classificadas como 1(bots). Penaliza falso Positivo
- **F1**:Representa m√©dia entre Precision e Recall, dando um peso igual √†s duas m√©tricas.

Normalmente ocorre um trade-off entre Precision e Recall, para aumentar uma devemos reduzir outra, por isso tamb√©m foi utilizado o F1-score, sendo a m√©trica de maior relev√¢ncia para a avalia√ß√£o de performance do modelo.

![precision e recall](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)

Agora que j√° entendemos as m√©tricas,vamos para o modelo

## Random Forest :deciduous_tree:

Ap√≥s todas as transforma√ß√µes realizadas, constatou-se que realmente os modelos baseados em arvore (como o XGBoost, ADA e Random Forest) foram os que mais performaram. Ap√≥s a otimiza√ß√£o dos hiper-par√¢metros dos modelos mencionados, o Random Forest foi modelo que melhor se ajustou ao problema e obteve as melhores m√©tricas.

Random Forest √© um modelo de Ensamble do tipo Baggin (Bootstrap Aggregating). Ensambles do tipo Baggin realizam diversos modelos em paralelo e combinam seus resultados para uma previs√£o final. O Random Forest, al√©m de criar v√°rias arvores em paralelo para estimar o resultado final, ainda utiliza subgrupos aleat√≥rios das features em cada √°rvore para criar uma floresta n√£o correlacionada de arvores de decis√£o.

As m√©tricas obtidas com nosso modelo foram

|    Modelo |           | RF_HPgrid1000_boruta |
|----------:|-----------|---------------------:|
| --------- | --------- | -------------------- |
|           | Treino    | Teste                |
| Accur√°cia | 0.865     | 0.806                |
| Precision | 0.87      |                0.811 |
|    Recall | 0.856     |                0.799 |
|        F1 | 0.885     |                0.831 |


### Avalia√ß√£o do modelo

#### Matriz de Confus√£o
O modelo constru√≠do obteve a seguinte matriz de confus√£o para o teste, considerando um treshhold padr√£o de 0.5

![ConfusionMatrixDisplay](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/Matriz%20%20de%20confus%C3%A3o%20teste.jpg)

Atrav√©s da matriz de confus√£o conseguimos observar a quantidade de:
- Falsos Postivos -> humanos identificados como bot de forma errada
- Verdadeiros Positivos -> bots corretamente identificados como bots
- Falsos Negativos -> bots que n√£o foram identificados como bots
- Verdadiero Negativo -> humanos corretamente identificados como humanos

A Matriz de confus√£o nos mostra a quantidade de observa√ß√µes corretamente identificadas na diagonal esquerda (\) e as observa√ß√µes identificadas de maneira errada na diagonal direita (/). E √© apartir dela que s√£o computadas as m√©tricas de avalia√ß√£o mencionadas anteriormente.

#### Curva ROC

Podemos alterar o comportamento da Matriz de confus√£o de de acordo com o treshold escolhido para rotula√ß√£o das observa√ß√µes. Em outras palavras, ao rodar o modelo para *N* observa√ß√µes ele retorna a probabilidade de que determinada observa√ß√£o seja um bot, e de acordo com o limiar de classifica√ß√£o escolhido para rotular determinada observa√ß√£o como bot a matriz de confus√£o √© alterada, e por consequencia os resultados das m√©tricas de avalia√ß√£o.

Assim se quisermos ser mais conservadores, rotulando como bot somente as observa√ß√µes com alta probabilidade, devemos AUMENTAR o limiar de classifica√ß√£o (treshold). Ao fazer isso por consequ√™ncia, deixaremos de identificar alguns bots por√©m reduziremos a quantidade de usu√°rios verdadeiros identificados como bot. Em outras palavras, assim  diminuimos os Verdadeiros Positivos e tamb√©m diminuimos os Falso Positivos.

Se diminuirmos nosso limiar de classifica√ß√£o, o oposto ir√° ocorrer.

E atrav√©s da Curva ROC, conseguimos plotar esse trade-off entre Verdadeiro positivo e Falso negativos de acordo com a varia√ß√£o do limiar escolhido (treshold)

![ROC](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/ROC.jpg)

AUC se refere a Area Under de Curve, ou √°rea abaixo da curva, evai de 0 at√© 1. Quanto maior seu valor, melhor o modelo ser√° capaz de identificar os Verdadeiros Positivos sem ocorrer em Falsos Positivos.

### Feature Importance -SHAP

Para analis√°rmos quais foram as features mais importantes para a avalia√ß√£o proposta pelo do modelo e como a varia√ß√£o de seus valores impacta no resultado final, foi utilizado o [SHAP](https://shap.readthedocs.io/en/latest/index.html) (SHapley Additive exPlanations). O SHAP utiliza conceitos da teoria dos jogos e √© capaz de demonstrar o quanto a altera√ß√£o de uma vari√°vel √© capaz de influenciar o resultado do modelo, nos ajudando a compreeender o funcionamento do modelo.

Ele ordena as features de acordo com o chamado Shapley Values, que, basicamente, mede o impacto de cada feature no modelo.

No gr√°fico abaixo, as features est√£o rankeadas, do maior para o menor, de acordo com o Shapley value geral de cada feature. Valores em vermelho, s√£o mais importante em avaliar se um perfil √© um bot ou n√£o.

![SHAP](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/SHAP.jpg)

Podemos observar que erificou-se que as 5 features mais significativas para o modelo foram:
- friends_followers_ratio
- Listed_count
- Followers_count
- Listed_growth_rate
- followers_growth_rate

Isso nos mostra que a quantidade de conex√µes, sejam seguidos ou seguidores, que um perfil possui e a taxa decrescimento que essas conex√µes s√£o realizadas s√£o fatores preponderantes para determinar se determinar se um perfil ser√° um bot ou um humano. Oque confirma um conhecimento heur√≠stico das redes sociais, humanos querem se conectar com outros humanos, n√£o querendo se associar com perfis falsos/bots.

## Conclus√£o  :confetti_ball:

Caso voc√™ tenha dado uma olhada no artigo cient√≠fico utilizado como fonte de dados do modelo, pode observar que a proposta do artigo, como falado anteriormente, √© a de cria√ß√£o de um dataset que seja representativo do mundo real. E n√£o a cria√ß√£o de um modelo de machine learning capaz de identificar bots e humanos.

No final do artigo os autores testam alguns modelos propostos por outros artigos cient√≠ficos utilizando o dataset gerado, e apresentam os resultados de cada modelo. Vale ressaltar que os modelos testados foram propostos por artigos recentes, o mais antigo √© de 2011 sendo qua agrande maioria se concentra entre os anos de 2018 e 2020. 

Se compararmos nosso modelo com os modelos testados, nosso modelo ocupa a 2¬™ coloca√ß√£o no ranking! Estando apenas cerca de 2% abaixo do modelo que melhor performou, observando o F1 score. √â oque podemos observar na reprodu√ß√£o da tabela observada no artigo, com o resultado do nosso modelo.

![Compara√ß√£o de resultados](https://raw.githubusercontent.com/tnorio/Machine_Learning/main/Detec%C3%A7%C3%A3o%20de%20Perfis%20Automatizados%20-%20Twibot20/images/resultados.jpg)

Ao an√°lisar o artigo do melhor modelo avaliado, pude perceber que uma das features mais importantes em seu modelo, foi uma m√©trica de compara√ß√£o do nome e da descri√ß√£o de cada perfil. Que s√≥ foi capaz de ser criada ap√≥s a extra√ß√£o de dados de centenas de milhares de usu√°rios. Claramente este tipo de feature n√£o seria poss√≠vel ser craido por este projeto, visto que demandaria um esfor√ßo computacional/t√©cnico que n√£o esteve dispon√≠vel na elabora√ß√£o deste projeto.

De qualquer forma estou muito satisfeito com o resultado, apenas 2% de diferen√ßa no F1 score sem a necessidade de minearar dados de centenas de milhares de usu√°rios na plataforma.

### Considera√ß√µes finais

A complexidade e das redes sociais e comportamento humano, torna este um problema altamente din√¢mico. Praticamente todos os dias novas formas de enganar as medidas de preven√ß√£o a perfis automatizados s√£o criadas e adotadas pelos bots das redes sociais. E ao mesmo tempo novas formas de evitar o surgimento e propaga√ß√£o de perfis fake s√£o implementadas pelas plataformas. Oque torna a busca por uma solu√ß√£o um trabalho constante.

As features dos  utilizadas no modelo, com excess√£o das features baseadas em texto, pois os assuntos nas redes s√£o altamente din√¢micos e variam de acordo com a regi√£o / acontecimentos mais recentes, foram features que podem continuar a ser aplicadas em modelos futuros e que n√£o possuem vieses preconceituosos contra determinados grupos de usu√°rios.  Sendo assim, este modelo se torna mais um passo na constante busca por um ambiente de intera√ß√µes sociais livre de manipula√ß√µes de fake news / spams.

## Bibliografia :book:

- [TwiBot-20: A Comprehensive Twitter Bot Detection Benchmark](https://www.researchgate.net/publication/355785254_TwiBot-20_A_Comprehensive_Twitter_Bot_Detection_Benchmark)
- [A one-class classification approach for bot detection on Twitter](https://www.sciencedirect.com/science/article/pii/S0167404820300031)
- [Online Human-Bot Interactions: Detection, Estimation, and Characterization](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3324593)
- [Detecting Twitter Fake Accounts using Machine Learning and Data Reduction Techniques](https://www.semanticscholar.org/paper/Detecting-Twitter-Fake-Accounts-using-Machine-and-Homsi-Nemri/a745f5458c992b83a0fb8da3fe1b0a240d155d60)
- [Fake Account Detection in Twitter Based on Minimum Weighted Feature](https://www.researchgate.net/publication/304569053_Fake_Account_Detection_in_Twitter_Based_on_Minimum_Weighted_Feature_set)
